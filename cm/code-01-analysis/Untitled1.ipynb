{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from curvaturemodel import curvature as curv \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/cmagri1/OneDrive - Johns Hopkins/git')\n",
    "from EncodingModel_cm296 import utils as emutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#where to get the images from\n",
    "PathToImgs = 'data-object2vec/stimuli'\n",
    "\n",
    "#where to load word2sense\n",
    "pathtoW2S = '../code-00-preprocessdataset/'\n",
    "Wrd2Sense = pd.read_csv(pathtoW2S + \"ThingsWrd2Sns.txt\", sep=\",\")\n",
    "WordInf = pd.read_csv(pathtoW2S + \"KeptTHINGSInfo.txt\", sep=\",\")['Word'].to_numpy()\n",
    "# .Word.to_numpy()\n",
    "# WordInf= ImgInfo.Word.to_numpy() ##to find the words that are images in THINGS dataset\n",
    "\n",
    "\n",
    "pathtoTHINGS = '../../../../THINGSdataset/Main/images'\n",
    "savepath = '../../../data-00/'\n",
    "pretrainedModel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as tr\n",
    "from torchvision import transforms as tt\n",
    "\n",
    "def listdir(dir, path=True):\n",
    "    files = os.listdir(dir)\n",
    "    files = [f for f in files if f != '.DS_Store']\n",
    "    files = sorted(files)\n",
    "    if path:\n",
    "        files = [os.path.join(dir, f) for f in files]\n",
    "    return files\n",
    "\n",
    "imagenet_mean = (0.485, 0.456, 0.406)\n",
    "imagenet_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "def image_to_tensor(image, resolution=None,paddingval=None,padding_mode = 'constant', do_imagenet_norm=False, do_padding = True):\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image).convert('LA')     \n",
    "        if image.width != image.height:     # if not square image, crop the long side's edges to make it square\n",
    "            r = min(image.width, image.height)\n",
    "            image = tr.center_crop(image, (r, r))\n",
    "        if do_padding:     # if not square image, crop the long side's edges to make it square\n",
    "            image = tr.pad(image, padding=paddingval, padding_mode=padding_mode, fill=0)\n",
    "            # image = tr.pad(input=data, mode='reflect', value=0)\n",
    "        if resolution is not None:#f size is an int, smaller edge of the image will be matched to this number\n",
    "            image = tr.resize(image, resolution)\n",
    "    \n",
    "        image = tr.to_tensor(image)\n",
    "        if do_imagenet_norm:\n",
    "            image = imagenet_norm(image)\n",
    "    return image\n",
    "\n",
    "def imagenet_norm(image):\n",
    "    dims = len(image.shape)\n",
    "    if dims < 4:\n",
    "        image = [image]\n",
    "    image = [tr.normalize(img, mean=imagenet_mean, std=imagenet_std) for img in image]\n",
    "    image = torch.stack(image, dim=0)\n",
    "    if dims < 4:\n",
    "        image = image.squeeze(0)\n",
    "    return image\n",
    "\n",
    "def compute_features_curvature(model, conditionsPath, resolutionval = 227,WordInf =[],paddingval=0,padding_mode='constant'):\n",
    "    #takes model and loads the features for that image, needs path to of files in directory\n",
    "\n",
    "    conditions = listdir(conditionsPath)\n",
    "    # print(len(conditions))\n",
    "\n",
    "    if WordInf != np.array([]):\n",
    "        new_conditions = []\n",
    "        for c in conditions:\n",
    "            w = c.split('/')[-1]\n",
    "            if w in WordInf:\n",
    "                new_conditions.append(c)\n",
    "        conditions = new_conditions\n",
    "\n",
    "\n",
    "    condition_features = {}\n",
    "    for c in tqdm(conditions):\n",
    "        c_name = c.split('/')[-1]\n",
    "        \n",
    "        stimuli = listdir(c)\n",
    "        #resize according to resolution and square the image\n",
    "        stimuli = [image_to_tensor(s, resolution=resolutionval,paddingval=paddingval,padding_mode = padding_mode) for s in stimuli]\n",
    "        stimuli = torch.stack(stimuli)\n",
    "       \n",
    "        #average across the same category\n",
    "        feats = model.forward(stimuli).numpy()\n",
    "    \n",
    "#         condition_features[c_name] = feats\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Compute DNN features\n",
    "def object_by_feature(PathToImgs,namemodel,keyword, savepath,WordList=[]):\n",
    "\n",
    "    namefile = savepath+ keyword + '_' + namemodel \n",
    "        \n",
    "    if os.path.isfile(namefile+\".csv\"): #if it's already saves\n",
    "        \n",
    "        print('loading file with '+ keyword+ ' stimuli features for ' + namemodel + ' model')\n",
    "        features = pd.read_csv(namefile+\".csv\"  , sep=\",\", header=None, index_col=0)\n",
    "        condition_features = {}\n",
    "        for index, row in features.iterrows():\n",
    "            condition_features[index] = row \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        print('Computing '+ keyword+ ' stimuli features for ' + namemodel + ' model')\n",
    "        #Specify the model\n",
    "        if namemodel is 'Curvature':\n",
    "            model = curv.CurvatureModel()\n",
    "        condition_features = compute_features_curvature(model, PathToImgs,WordInf = WordList)\n",
    "#         features = \n",
    "        pd.DataFrame(condition_features).transpose().to_csv(namefile+\".csv\", index = True, header=False)\n",
    "#         features.to_csv(namefile+\".csv\", index = True, header=False)\n",
    "        np.save(namefile,condition_features)\n",
    "#     layer_by_features[ilayer] = features; #create multistructure with all layers\n",
    "    return condition_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmagri1/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:53: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing object2vec stimuli features for Curvature model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size 320 1 9 9, expected input[10, 2, 227, 227] to have 1 channels, but got 2 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ff6c3c9e551a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Curvature'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'object2vec'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mobject2vec_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_by_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPathToImgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msavepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-fba2472817b9>\u001b[0m in \u001b[0;36mobject_by_feature\u001b[0;34m(PathToImgs, namemodel, keyword, savepath, WordList)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnamemodel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;34m'Curvature'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCurvatureModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mcondition_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_features_curvature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPathToImgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWordInf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#         features =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamefile\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-0339cdb9be63>\u001b[0m in \u001b[0;36mcompute_features_curvature\u001b[0;34m(model, conditionsPath, resolutionval, WordInf, paddingval, padding_mode)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#average across the same category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstimuli\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m#         condition_features[c_name] = feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive - Johns Hopkins/Project-Word2Sense/Code-Python/semantic-code/cm/code-01-analysis/curvaturemodel/curvature.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilt_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size 320 1 9 9, expected input[10, 2, 227, 227] to have 1 channels, but got 2 channels instead"
     ]
    }
   ],
   "source": [
    "#Compute features of CNN\n",
    "#---------Object2Vect-----------------\n",
    "model = 'Curvature'\n",
    "keyword = 'object2vec'\n",
    "object2vec_features = object_by_feature(PathToImgs,model,keyword,savepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
