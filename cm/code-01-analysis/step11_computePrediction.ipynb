{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "import utilsCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Word2Vec\n",
    "filename = 'ThingsWrd2Vec_subset.txt'\n",
    "filepath = '../../../data-10/'\n",
    "Wrd2Vec = pd.read_csv(filepath + filename,sep=',',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running PCA Analysis to Compare Word2Sense and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame as pddf\n",
    "\n",
    "pca_W2Vec = PCA(n_components=125)\n",
    "pca_W2Vec.fit(Wrd2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathtofile = '../../../data-07/'\n",
    "W2S_subset = pd.read_csv(pathtofile + \"ThingsWrd2Sns_subset.txt\", sep=\",\",index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_W2S = PCA(n_components=125)\n",
    "pca_W2S.fit(W2S_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_ratio = {}\n",
    "pca_ratio['W2Sense']= []\n",
    "pca_ratio['W2Vec']= []\n",
    "pca_ratio['W2Sense']= pca_W2S.explained_variance_ratio_\n",
    "pca_ratio['W2Vec']= pca_W2Vec.explained_variance_ratio_\n",
    "pca_ratio_pd = pddf.from_dict(pca_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(data= pca_ratio_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking into Predictions for Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Y_embeddings_subset = Wrd2Vec.values[:,:].astype(np.float)\n",
    "Y_embeddings_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer =  {'conv_1','conv_5','fc_3'}\n",
    "Sub = [1,2,3,4]\n",
    "\n",
    "pretrained_val = True\n",
    "\n",
    "datapath = '../../../data-00/'\n",
    "savepath = '../../../data-11/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIpath = '../../../data-04/'\n",
    "nsample = 12\n",
    "WrdThingsInfo = pd.read_csv(WIpath + 'KeptTHINGSInfo_n' + str(nsample) +'.csv',sep=',',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = {'EVC','ObjectROI'}\n",
    "# ROI = {'EVC'}\n",
    "keyword = {'DNNActvtn','ROIpred'}\n",
    "# keyword = {'ROIpred'}\n",
    "Keepncomps = list(range(2,42,2))\n",
    "# Keepncomps = [2]\n",
    "\n",
    "Ypredict = 'Word2Vec'\n",
    "\n",
    "for ikeyword in keyword:\n",
    "    for ilayer in layer:\n",
    "        \n",
    "        if ikeyword is 'ROIpred':\n",
    "            \n",
    "            for iROI in ROI: \n",
    "                predictor_variable = {}\n",
    "                for iSub in Sub:\n",
    "                    Subfile = datapath +  \"ROIpred_Sub\" + str(iSub) + '_' + iROI + \"_\" + ilayer \n",
    "                    if not pretrained_val:\n",
    "                        Subfile = Subfile + '_untrained'\n",
    "                    \n",
    "                    thisSub = np.load(Subfile + '.npy')\n",
    "                            \n",
    "                    #load ROIpred as predictor variable\n",
    "                    if iSub is 1:\n",
    "                        predictor_variable = thisSub\n",
    "                    else:\n",
    "                        predictor_variable = np.append( predictor_variable , thisSub, axis = 1)\n",
    "                    \n",
    "                predictor_variable_sub = predictor_variable[WrdThingsInfo['old_index']]\n",
    "                    \n",
    "\n",
    "                for icomps in Keepncomps:\n",
    "                    filename = 'Predict' + Ypredict + '_' + ikeyword + '_' +iROI + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "\n",
    "                    if not pretrained_val:\n",
    "                        filename = filename+'_untrained'\n",
    "                        \n",
    "                    if not os.path.isfile(savepath + filename + '.npy'):\n",
    "                        mean_r = utilsCM.iter_cvregress(predictor_variable_sub,Y_embeddings_subset,ikeyword,ilayer,icomps,iROI,savefolder = savepath, Ypredict=Ypredict,pretrained = pretrained_val)\n",
    "#                     utilsCM.make_figure(mean_r,ikeyword,ilayer,icomps,iROI, figurepath = 'figures-05/')\n",
    "#                     print(mean_r)\n",
    "        \n",
    "        \n",
    "        elif ikeyword is 'DNNActvtn':\n",
    "            predictor_variable_file = datapath +  \"things_\" + ilayer \n",
    "            if not pretrained_val:\n",
    "                predictor_variable_file = predictor_variable_file + '_untrained'\n",
    "            \n",
    "            predictor_variable = pd.read_csv(predictor_variable_file + '.csv', header=None, index_col=0).iloc[:,:].to_numpy()            \n",
    "            predictor_variable_sub = predictor_variable[WrdThingsInfo['old_index']]\n",
    "\n",
    "            for icomps in Keepncomps:\n",
    "                filename = 'Predict' + Ypredict + '_'  + ikeyword + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                \n",
    "                if not pretrained_val:\n",
    "                    filename = filename +'_untrained'\n",
    "                                            \n",
    "                if not os.path.isfile(savepath + filename + '.npy'):\n",
    "                    mean_r = utilsCM.iter_cvregress(predictor_variable_sub,Y_embeddings_subset,ikeyword,ilayer,icomps,savefolder = savepath, Ypredict=Ypredict, pretrained = pretrained_val)\n",
    "                \n",
    "#                 utilsCM.make_figure(mean_r,ikeyword,ilayer,icomps, figurepath = 'figures-05/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresh_bonf = utilsCM.p2r(.05/Y_embeddings_subset.shape[1], Y_embeddings_subset.shape[0])\n",
    "figurepath='../../../figures-11/'\n",
    "\n",
    "ROI = {'EVC','ObjectROI'}\n",
    "keyword = {'DNNActvtn','ROIpred'}\n",
    "Keepncomps = list(range(2,42,2))\n",
    "pretrained_val = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame as pddf\n",
    "\n",
    "savepath = '../../../data-11/'\n",
    "figurepath = '../../../figures-11/'\n",
    "layer = {'fc_3'}\n",
    "pretrained_vec = [True, False]\n",
    "##Showing histograms for senses above threshold\n",
    "\n",
    "Ypredict = 'Word2Vec'\n",
    "\n",
    "myDict_count = {}\n",
    "myDict_mean = {}\n",
    "myDict_max = {}\n",
    "myDict_median = {}\n",
    "\n",
    "\n",
    "for ilayer in layer:\n",
    "    for pretrained_val in pretrained_vec:\n",
    "        for ikeyword in keyword:            \n",
    "            for icomps in Keepncomps:\n",
    "                thisPrediction = []\n",
    "                \n",
    "                if ikeyword is 'DNNActvtn':\n",
    "\n",
    "                    filename = 'Predict' + Ypredict + '_' + ikeyword + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                    DictKey = ikeyword\n",
    "\n",
    "                    if not pretrained_val:\n",
    "                        filename = filename + '_untrained'\n",
    "                        DictKey = DictKey + '_untrained'\n",
    "        \n",
    "                    if DictKey not in myDict_count:\n",
    "                        myDict_count[DictKey] = []\n",
    "                        myDict_mean[DictKey] = []\n",
    "                        myDict_max[DictKey] = []\n",
    "                        myDict_median[DictKey] = []\n",
    "                        \n",
    "                    thisPrediction = np.load(savepath + filename + '.npy')\n",
    "                    pred_thresh = thisPrediction[thisPrediction>tresh_bonf]\n",
    "                    myDict_count[DictKey].append(pred_thresh.shape[0])\n",
    "                    myDict_mean[DictKey].append(pred_thresh.mean())\n",
    "                    myDict_max[DictKey].append(pred_thresh.max())\n",
    "                    myDict_median[DictKey].append(np.median(pred_thresh))\n",
    "                    utilsCM.make_figure(pred_thresh,ikeyword,ilayer,icomps,figure_size=(50,20),figure_path = figurepath, Ypredict=Ypredict,font_size=40,pretrained = pretrained_val)\n",
    "                    \n",
    "            \n",
    "                elif ikeyword is 'ROIpred':\n",
    "                \n",
    "                    for iROI in ROI:\n",
    "                        filename = 'Predict' + Ypredict + '_' + ikeyword + '_' +iROI + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                        DictKey = iROI\n",
    "                        if not pretrained_val:\n",
    "                            filename = filename +'_untrained'\n",
    "                            DictKey = DictKey + '_untrained'\n",
    "\n",
    "                        if DictKey not in myDict_count:\n",
    "                            myDict_count[DictKey] = []\n",
    "                            myDict_mean[DictKey] = []\n",
    "                            myDict_max[DictKey] = []\n",
    "                            myDict_median[DictKey] = []\n",
    "                        \n",
    "                        thisPrediction = np.load(savepath + filename + '.npy')\n",
    "                        pred_thresh = thisPrediction[thisPrediction>tresh_bonf]\n",
    "                        myDict_count[DictKey].append(pred_thresh.shape[0])\n",
    "                        myDict_mean[DictKey].append(pred_thresh.mean())\n",
    "                        myDict_max[DictKey].append(pred_thresh.max())\n",
    "                        myDict_median[DictKey].append(np.median(pred_thresh))\n",
    "                        utilsCM.make_figure(pred_thresh,ikeyword,ilayer,icomps,iROI,figure_size=(50,20),figure_path = figurepath, Ypredict=Ypredict,font_size=40,pretrained = pretrained_val)\n",
    "                        \n",
    "                        \n",
    "        \n",
    "    myDict_count['PCs'] = []\n",
    "    myDict_mean['PCs'] = []\n",
    "    myDict_max['PCs'] = []\n",
    "    myDict_median['PCs'] = []\n",
    "    myDict_count['Metric'] = []\n",
    "    myDict_mean['Metric'] = []\n",
    "    myDict_max['Metric'] = []\n",
    "    myDict_median['Metric'] = []\n",
    "    for i in range(2,42,2):\n",
    "        myDict_count['PCs'].append(i)\n",
    "        myDict_mean['PCs'].append(i)\n",
    "        myDict_max['PCs'].append(i)\n",
    "        myDict_median['PCs'].append(i)\n",
    "        myDict_count['Metric'].append('count')\n",
    "        myDict_mean['Metric'].append('mean')\n",
    "        myDict_max['Metric'].append('max')\n",
    "        myDict_median['Metric'].append('median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pddf.from_dict(myDict_count).set_index('PCs')\n",
    "df_mean = pddf.from_dict(myDict_mean).set_index('PCs')\n",
    "df_max = pddf.from_dict(myDict_max).set_index('PCs')\n",
    "df_median = pddf.from_dict(myDict_median).set_index('PCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvalues = pd.concat([df_count, df_mean,df_max,df_median], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.lineplot(data= allvalues[allvalues['Metric'] == 'mean'].iloc[:,0:6]).set_title('Mean')\n",
    "plt.savefig(figurepath + \"Mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= allvalues[allvalues['Metric'] == 'median'].iloc[:,0:6]).set_title('Median')\n",
    "plt.savefig(figurepath + \"Median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= allvalues[allvalues['Metric'] == 'max'].iloc[:,0:6]).set_title('Max')\n",
    "plt.savefig(figurepath + \"Max.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= allvalues[allvalues['Metric'] == 'count'].iloc[:,0:6]).set_title('Count')\n",
    "plt.savefig(figurepath + \"Count.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ikeyword in keyword:\n",
    "    for ilayer in layer:\n",
    "        \n",
    "        if ikeyword is 'ROIpred':\n",
    "            \n",
    "            for iROI in ROI: \n",
    "                predictor_variable = {}\n",
    "                for iSub in Sub:\n",
    "                    Subfile = datapath +  \"ROIpred_Sub\" + str(iSub) + '_' + iROI + \"_\" + ilayer \n",
    "                    if not pretrained_val:\n",
    "                        Subfile = Subfile + '_untrained'\n",
    "                    \n",
    "                    thisSub = np.load(Subfile + '.npy')\n",
    "                            \n",
    "                    #load ROIpred as predictor variable\n",
    "                    if iSub is 1:\n",
    "                        predictor_variable = thisSub\n",
    "                    else:\n",
    "                        predictor_variable = np.append( predictor_variable , thisSub, axis = 1)\n",
    "                    \n",
    "                predictor_variable_sub = predictor_variable[WrdThingsInfo['old_index']]\n",
    "                pca_ROI = PCA(n_components=60)\n",
    "                pca_ROI.fit(predictor_variable_sub)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
