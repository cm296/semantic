{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from curvaturemodel import curvature as curv \n",
    "from curvaturemodel import edge as edg \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/cmagri1/OneDrive - Johns Hopkins/git')\n",
    "from EncodingModel_cm296 import utils as emutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = '../../../data-00/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as transforms\n",
    "\n",
    "\n",
    "def listdir(dir, path=True):\n",
    "    files = os.listdir(dir)\n",
    "    files = [f for f in files if f != '.DS_Store']\n",
    "    files = sorted(files)\n",
    "    if path:\n",
    "        files = [os.path.join(dir, f) for f in files]\n",
    "    return files\n",
    "\n",
    "imagenet_mean = (0.485, 0.456, 0.406)\n",
    "imagenet_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "def image_to_model(image,model):\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image)\n",
    "#         .convert('LAD')\n",
    "        image = transforms.to_grayscale(image)\n",
    "        image = transforms.resize(image, (96, 96))    # Or whatever resolution you want\n",
    "        image = transforms.to_tensor(image)\n",
    "        image = transforms.normalize(image, mean=(0.5,), std=(0.5,))\n",
    "        with torch.no_grad():\n",
    "            features = model(image.unsqueeze(dim=0)).squeeze(dim=0)\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def compute_features_curvature(model, conditionsPath,WordInf =[]):\n",
    "    #takes model and loads the features for that image, needs path to of files in directory\n",
    "\n",
    "    conditions = listdir(conditionsPath)\n",
    "\n",
    "    #If it's THINGS this ensures we only pick up images from List of 1470\n",
    "    if len(WordInf) > 0:\n",
    "        new_conditions = []\n",
    "        for c in conditions:\n",
    "            w = c.split('/')[-1]\n",
    "            if w in WordInf:\n",
    "                new_conditions.append(c)\n",
    "        conditions = new_conditions\n",
    "\n",
    "    condition_features = {}\n",
    "    for c in tqdm(conditions):\n",
    "        c_name = c.split('/')[-1]\n",
    "        \n",
    "        stimuli = listdir(c)\n",
    "        \n",
    "        #resize according to resolution and square the image\n",
    "        features = [image_to_model(s,model) for s in stimuli]\n",
    "        \n",
    "        features = torch.stack(features)\n",
    "        feats = features.mean(dim=0).cpu().numpy()\n",
    "        condition_features[c_name] = feats\n",
    "    return condition_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Compute DNN features\n",
    "def object_by_feature(namemodel,keyword, savepath,WordList=[]):\n",
    "\n",
    "    namefile = savepath+ keyword + '_' + namemodel \n",
    "        \n",
    "    if os.path.isfile(namefile+\".csv\"): #if it's already saves\n",
    "        \n",
    "        print('loading file with '+ keyword+ ' stimuli features for ' + namemodel + ' model')\n",
    "        features = pd.read_csv(namefile+\".csv\"  , sep=\",\", header=None, index_col=0)\n",
    "        condition_features = {}\n",
    "        for index, row in features.iterrows():\n",
    "            condition_features[index] = row \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if keyword is 'things':\n",
    "            PathToImgs = '../../../../THINGSdataset/Main/images'\n",
    "            WordList = pd.read_csv('../code-00-preprocessdataset/' + \"KeptTHINGSInfo.txt\", sep=\",\")['Word'].to_numpy()\n",
    "        elif keyword is 'object2vec':\n",
    "            PathToImgs = 'data-object2vec/stimuli'\n",
    "        \n",
    "    \n",
    "        \n",
    "        print('Computing '+ keyword+ ' stimuli features for ' + namemodel + ' model')\n",
    "        #Specify the model\n",
    "        if namemodel is 'Curvature':\n",
    "            model = curv.CurvatureModel()\n",
    "        elif namemodel is 'Edge':\n",
    "            model = edg.EdgeModel()\n",
    "            \n",
    "        condition_features = compute_features_curvature(model, PathToImgs,WordInf = WordList)\n",
    "#         print(condition_features)\n",
    "\n",
    "        \n",
    "#         pd.DataFrame(condition_features).transpose().to_csv(namefile+\".csv\", index = True, header=False)\n",
    "        np.save(namefile,condition_features)\n",
    "    return condition_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1470 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing things stimuli features for Curvature model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1470/1470 [15:00<00:00,  1.63it/s]\n"
     ]
    }
   ],
   "source": [
    "#Compute features of CNN\n",
    "#---------Object2Vect-----------------\n",
    "model = 'Curvature'\n",
    "keyword = 'things'\n",
    "object2vec_features = object_by_feature(model,keyword,savepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'object2vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-302ae67f2a26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Edge'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'object2vec'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mobject2vec_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_by_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msavepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-e8e87eb6f71e>\u001b[0m in \u001b[0;36mobject_by_feature\u001b[0;34m(namemodel, keyword, savepath, WordList)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mPathToImgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../../../THINGSdataset/Main/images'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mWordList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../code-00-preprocessdataset/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"KeptTHINGSInfo.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mobject2vec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mPathToImgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data-object2vec/stimuli'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'object2vec' is not defined"
     ]
    }
   ],
   "source": [
    "#Compute features of CNN\n",
    "#---------Object2Vect-----------------\n",
    "model = 'Edge'\n",
    "keyword = 'object2vec'\n",
    "object2vec_features = object_by_feature(model,keyword,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
