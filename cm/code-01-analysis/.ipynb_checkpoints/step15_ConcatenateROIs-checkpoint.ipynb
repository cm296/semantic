{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utilsCM\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load word2sense\n",
    "#already preprocessed in MATLAB so that Wrd2Sns and THINGs overlap --> we have IMAGES, LABELS and SENSES\n",
    "pathtofile = '../code-00-preprocessdataset/'\n",
    "Y_embeddings = pd.read_csv(pathtofile + \"ThingsWrd2Sns.txt\", sep=\",\")\n",
    "Y_embeddings = Y_embeddings.values[:,1:Y_embeddings.shape[1]-1].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = {'ROIpred'}\n",
    "\n",
    "\n",
    "# layer =  {'conv_1', 'conv_2','conv_3','conv_4','conv_5'}\n",
    "# layer =  {'conv_1','conv_5','fc_3'}\n",
    "layer =  {'conv_5'}\n",
    "\n",
    "Sub = [1,2,3,4]\n",
    "\n",
    "\n",
    "pretrained_val = False\n",
    "\n",
    "datapath = '../../../data-00/'\n",
    "savepath = '../../../data-01/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make object selective ROIs by adding together LOC and PFS\n",
    "objectROI = {'LOC','PFS'}\n",
    "for ilayer in layer:\n",
    "    for iSub in Sub:        \n",
    "            \n",
    "        if not pretrained_val:\n",
    "            filename = datapath +  \"ROIpred_Sub\" + str(iSub) + '_ObjectROI_' + ilayer + '_untrained.npy'\n",
    "        else:\n",
    "            filename = datapath +  \"ROIpred_Sub\" + str(iSub) + '_ObjectROI_' + ilayer + '.npy'\n",
    "\n",
    "        if not os.path.isfile(filename): #if it's not there\n",
    "            predictor_variable = {}\n",
    "            for iROI in objectROI:\n",
    "                if not pretrained_val:\n",
    "                    thisROI = np.load(datapath +  \"ROIpred_Sub\" + str(iSub) + '_' + iROI + \"_\" + ilayer + '_untrained.npy')\n",
    "                else:\n",
    "                    thisROI = np.load(datapath +  \"ROIpred_Sub\" + str(iSub) + '_' + iROI + \"_\" + ilayer + '.npy')\n",
    "            \n",
    "                #load ROIpred as predictor variable\n",
    "                if len(predictor_variable) is 0:\n",
    "                    predictor_variable = thisROI\n",
    "                else:\n",
    "                    predictor_variable = np.append( predictor_variable , thisROI, axis = 1)    \n",
    "            np.save(filename,predictor_variable)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make scene selective ROIs by adding together OPA and OPA\n",
    "objectROI = {'PPA','OPA'}\n",
    "for ilayer in layer:\n",
    "    for iSub in Sub:        \n",
    "            \n",
    "        if not pretrained_val:\n",
    "            filename = datapath +  \"ROIpred_Sub\" + str(iSub) + '_SceneROI_' + ilayer + '_untrained.npy'\n",
    "        else:\n",
    "            filename = datapath +  \"ROIpred_Sub\" + str(iSub) + '_SceneROI_' + ilayer + '.npy'\n",
    "\n",
    "        if not os.path.isfile(filename): #if it's not there\n",
    "            predictor_variable = {}\n",
    "            for iROI in objectROI:\n",
    "                if not pretrained_val:\n",
    "                    thisROI = np.load(datapath +  \"ROIpred_Sub\" + str(iSub) + '_' + iROI + \"_\" + ilayer + '_untrained.npy')\n",
    "                else:\n",
    "                    thisROI = np.load(datapath +  \"ROIpred_Sub\" + str(iSub) + '_' + iROI + \"_\" + ilayer + '.npy')\n",
    "            \n",
    "                #load ROIpred as predictor variable\n",
    "                if len(predictor_variable) is 0:\n",
    "                    predictor_variable = thisROI\n",
    "                else:\n",
    "                    predictor_variable = np.append( predictor_variable , thisROI, axis = 1)    \n",
    "            np.save(filename,predictor_variable)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-fold regression, independet variable: 2 PCs retained of ROIpred from SceneROI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmagri1/OneDrive - Johns Hopkins/Project-Word2Sense/Code-Python/semantic-code/cm/code-01-analysis/utilsCM.py:179: RuntimeWarning: Mean of empty slice\n",
      "  mean_r = np.nanmean(rs, axis=0) #TO handle Nans, since the feature space is so sparse\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4fee69c1fee1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m                         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'PredictSENSES_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mikeyword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0miROI\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0milayer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0micomps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'PCs_untrained'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavepath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         \u001b[0mmean_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutilsCM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_cvregress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor_variable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mikeyword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0milayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0micomps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miROI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msavefolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msavepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;31m#                     utilsCM.make_figure(mean_r,ikeyword,ilayer,icomps,iROI, figurepath = 'figures-01/')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#                     print(mean_r)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/OneDrive - Johns Hopkins/Project-Word2Sense/Code-Python/semantic-code/cm/code-01-analysis/utilsCM.py\u001b[0m in \u001b[0;36miter_cvregress\u001b[0;34m(X_features, Y, keyword, ilayer, pc, iROI, k, savefolder, Ypredict, pretrained)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msavefolder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miROI\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Predict'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mYpredict\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0miROI\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0milayer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'PCs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Predict'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mYpredict\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0milayer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'PCs'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "ROI = {'EVC','ObjectROI','SceneROI'}\n",
    "# ROI = {'EVC'}\n",
    "keyword = {'DNNActvtn','ROIpred'}\n",
    "# keyword = {'ROIpred'}\n",
    "Keepncomps = list(range(2,42,2))\n",
    "# Keepncomps = [2]\n",
    "pretrained_val = True\n",
    "\n",
    "\n",
    "for ikeyword in keyword:\n",
    "    for ilayer in layer:\n",
    "        \n",
    "        if ikeyword is 'ROIpred':\n",
    "            \n",
    "            for iROI in ROI: \n",
    "                predictor_variable = {}\n",
    "                for iSub in Sub:\n",
    "                    if not pretrained_val:\n",
    "                        thisSub = np.load(datapath +  \"ROIpred_Sub\" + str(iSub) + '_' + iROI + \"_\" + ilayer + '_untrained.npy')\n",
    "                    else:\n",
    "                        thisSub = np.load(datapath +  \"ROIpred_Sub\" + str(iSub) + '_' + iROI + \"_\" + ilayer + '.npy')\n",
    "                            \n",
    "                    #load ROIpred as predictor variable\n",
    "                    if iSub is 1:\n",
    "                        predictor_variable = thisSub\n",
    "                    else:\n",
    "                        predictor_variable = np.append( predictor_variable , thisSub, axis = 1)\n",
    "\n",
    "                for icomps in Keepncomps:\n",
    "                    if pretrained_val:\n",
    "                        filename = 'PredictSENSES_' + ikeyword + '_' +iROI + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                    else:\n",
    "                        filename = 'PredictSENSES_' + ikeyword + '_' +iROI + '_'+ ilayer + '_'+ str(icomps) +'PCs_untrained'\n",
    "                    if not os.path.isfile(savepath + filename + '.npy'):\n",
    "                        mean_r = utilsCM.iter_cvregress(predictor_variable,Y_embeddings,ikeyword,ilayer,icomps,iROI,savefolder = savepath, pretrained = pretrained_val)\n",
    "#                     utilsCM.make_figure(mean_r,ikeyword,ilayer,icomps,iROI, figurepath = 'figures-01/')\n",
    "#                     print(mean_r)\n",
    "        \n",
    "        \n",
    "        elif ikeyword is 'DNNActvtn':            \n",
    "            if not pretrained_val:\n",
    "                predictor_variable = pd.read_csv(datapath +  \"things_\" + ilayer + '_untrained.csv', header=None, index_col=0).iloc[:,:].to_numpy()\n",
    "            else:\n",
    "                predictor_variable = pd.read_csv(datapath +  \"things_\" + ilayer + '.csv', header=None, index_col=0).iloc[:,:].to_numpy()\n",
    "\n",
    "                \n",
    "            for icomps in Keepncomps:\n",
    "                if pretrained_val:\n",
    "                    filename = 'PredictSENSES_' + ikeyword + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                else:\n",
    "                    filename = 'PredictSENSES_' + ikeyword +  '_'+ ilayer + '_'+ str(icomps) +'PCs_untrained'\n",
    "                    \n",
    "                if not os.path.isfile(savepath + filename + '.npy'):\n",
    "                    mean_r = utilsCM.iter_cvregress(predictor_variable,Y_embeddings,ikeyword,ilayer,icomps,savefolder = savepath, pretrained = pretrained_val)\n",
    "                \n",
    "#                 utilsCM.make_figure(mean_r,ikeyword,ilayer,icomps, figurepath = 'figures-01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tresh_bonf = utilsCM.p2r(.05/Y_embeddings.shape[1], 1470)\n",
    "figurepath='../../../figures-02/'\n",
    "\n",
    "ROI = {'EVC','ObjectROI'}\n",
    "keyword = {'DNNActvtn','ROIpred'}\n",
    "Keepncomps = list(range(2,42,2))\n",
    "pretrained_val = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame as pddf\n",
    "\n",
    "layer = {'conv_5'}\n",
    "pretrained_vec = [True, False]\n",
    "##Showing histograms for senses above threshold\n",
    "\n",
    "myDict_count = {}\n",
    "myDict_mean = {}\n",
    "myDict_max = {}\n",
    "myDict_median = {}\n",
    "\n",
    "\n",
    "for ilayer in layer:\n",
    "    for pretrained_val in pretrained_vec:\n",
    "        for ikeyword in keyword:            \n",
    "            for icomps in Keepncomps:\n",
    "                thisPrediction = []\n",
    "                if ikeyword is 'DNNActvtn':\n",
    "#                     count += 1\n",
    "                    if not pretrained_val:\n",
    "#                         count += 1\n",
    "                        filename = 'PredictSENSES_' + ikeyword + '_'+ ilayer + '_'+ str(icomps) +'PCs_untrained'\n",
    "                        DictKey = ikeyword + '_untrained'\n",
    "                    else:\n",
    "                        filename = 'PredictSENSES_' + ikeyword + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                        DictKey = ikeyword\n",
    "                    if DictKey not in myDict_count:\n",
    "                        myDict_count[DictKey] = []\n",
    "                        myDict_mean[DictKey] = []\n",
    "                        myDict_max[DictKey] = []\n",
    "                        myDict_median[DictKey] = []\n",
    "                        \n",
    "                    thisPrediction = np.load('../../../data-01/' + filename + '.npy')\n",
    "                    pred_thresh = thisPrediction[thisPrediction>tresh_bonf]\n",
    "                    myDict_count[DictKey].append(pred_thresh.shape[0])\n",
    "                    myDict_mean[DictKey].append(pred_thresh.mean())\n",
    "                    myDict_max[DictKey].append(pred_thresh.max())\n",
    "                    myDict_median[DictKey].append(np.median(pred_thresh))\n",
    "#                     utilsCM.make_figure(pred_thresh,ikeyword,ilayer,icomps,figure_size=(50,20),figure_path = figurepath,font_size=40,pretrained = pretrained_val)\n",
    "                    \n",
    "            \n",
    "                elif ikeyword is 'ROIpred':\n",
    "                \n",
    "                    for iROI in ROI:\n",
    "                        if not pretrained_val:\n",
    "                            filename = 'PredictSENSES_' + ikeyword + '_' +iROI + '_'+ ilayer + '_'+ str(icomps) +'PCs_untrained'\n",
    "                            DictKey = iROI + '_untrained'\n",
    "                            \n",
    "                        else:\n",
    "                            filename = 'PredictSENSES_' + ikeyword + '_' +iROI + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                            DictKey = iROI\n",
    "                        if DictKey not in myDict_count:\n",
    "                            myDict_count[DictKey] = []\n",
    "                            myDict_mean[DictKey] = []\n",
    "                            myDict_max[DictKey] = []\n",
    "                            myDict_median[DictKey] = []\n",
    "                        \n",
    "                        thisPrediction = np.load(savepath + filename + '.npy')\n",
    "                        pred_thresh = thisPrediction[thisPrediction>tresh_bonf]\n",
    "                        myDict_count[DictKey].append(pred_thresh.shape[0])\n",
    "                        myDict_mean[DictKey].append(pred_thresh.mean())\n",
    "                        myDict_max[DictKey].append(pred_thresh.max())\n",
    "                        myDict_median[DictKey].append(np.median(pred_thresh))\n",
    "                        utilsCM.make_figure(pred_thresh,ikeyword,ilayer,icomps,iROI,figure_size=(50,20),figure_path = figurepath,font_size=40,pretrained = pretrained_val)\n",
    "                        \n",
    "                        \n",
    "        \n",
    "    myDict_count['PCs'] = []\n",
    "    myDict_mean['PCs'] = []\n",
    "    myDict_max['PCs'] = []\n",
    "    myDict_median['PCs'] = []\n",
    "    myDict_count['Metric'] = []\n",
    "    myDict_mean['Metric'] = []\n",
    "    myDict_max['Metric'] = []\n",
    "    myDict_median['Metric'] = []\n",
    "    for i in range(2,42,2):\n",
    "        myDict_count['PCs'].append(i)\n",
    "        myDict_mean['PCs'].append(i)\n",
    "        myDict_max['PCs'].append(i)\n",
    "        myDict_median['PCs'].append(i)\n",
    "        myDict_count['Metric'].append('count')\n",
    "        myDict_mean['Metric'].append('mean')\n",
    "        myDict_max['Metric'].append('max')\n",
    "        myDict_median['Metric'].append('median')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pddf.from_dict(myDict_count).set_index('PCs')\n",
    "df_mean = pddf.from_dict(myDict_mean).set_index('PCs')\n",
    "df_max = pddf.from_dict(myDict_max).set_index('PCs')\n",
    "df_median = pddf.from_dict(myDict_median).set_index('PCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allvalues = pd.concat([df_count, df_mean,df_max,df_median], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.lineplot(data= allvalues[allvalues['Metric'] == 'mean'].iloc[:,0:6]).set_title('Mean')\n",
    "plt.savefig(figurepath + \"Mean.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= allvalues[allvalues['Metric'] == 'median'].iloc[:,0:6]).set_title('Median')\n",
    "plt.savefig(figurepath + \"Median.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= allvalues[allvalues['Metric'] == 'max'].iloc[:,0:6]).set_title('Max')\n",
    "plt.savefig(figurepath + \"Max.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data= allvalues[allvalues['Metric'] == 'count'].iloc[:,0:6]).set_title('Count')\n",
    "plt.savefig(figurepath + \"Count.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(range(2,42,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_PPA = 'PredictSENSES_' + 'ROIpred' + '_'+ 'PPA'+'_'+ ilayer+ '_'+ str(icomps) +'PCs'\n",
    "thisPrediction_PPA = np.load(savepath + filename_PPA + '.npy')\n",
    "\n",
    "filename_EVC = 'PredictSENSES_' + 'ROIpred' + '_'+ 'EVC'+'_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "thisPrediction_EVC = np.load( savepath + filename_EVC + '.npy')\n",
    "\n",
    "filename_LOC = 'PredictSENSES_' + 'ROIpred' + '_'+ 'LOC'+'_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "thisPrediction_LOC = np.load(savepath + filename_LOC + '.npy')\n",
    "\n",
    "# filename_DNN = 'PredictSENSES_' + 'DNNActvtn' +'_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "# thisPrediction_DNN = np.load('../../../data-01/' + filename_DNN + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisPrediction_PPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisPrediction_EVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisPrediction_LOC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
