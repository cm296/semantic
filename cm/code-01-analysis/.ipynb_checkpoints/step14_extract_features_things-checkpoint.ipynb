{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "sys.path.append('/Users/cmagri1/OneDrive - Johns Hopkins/git')\n",
    "from torch import nn\n",
    "import torch\n",
    "from torchvision.models.alexnet import alexnet\n",
    "from tqdm import tqdm\n",
    "\n",
    "from EncodingModel_cm296 import utils as emutils\n",
    "from EncodingModel_cm296 import feature_extractor as emfe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from utilsCM import Subject\n",
    "from utilsCM import cv_regression #Predicting fMRI reponses with features (Alexnet activations) \n",
    "#cv_regression computes cross-validated ridge regression. cross-validation groupings were pre-set based\n",
    "#on fMRI design. 9-categories out, 9 folds. r is averaged over folds, weights are computed over all data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load word2sense\n",
    "#already preprocessed in MATLAB so that Wrd2Sns and THINGs overlap --> we have IMAGES, LABELS and SENSES\n",
    "pathtofile = '../code-00-preprocessdataset/'\n",
    "Wrd2Sense = pd.read_csv(pathtofile + \"ThingsWrd2Sns.txt\", sep=\",\")\n",
    "ImgInfo = pd.read_csv(pathtofile + \"KeptTHINGSInfo.txt\", sep=\",\")\n",
    "pathtoTHINGS = '/Users/cmagri1/OneDrive - Johns Hopkins/Project-Word2Sense/THINGSdataset/Main/images'\n",
    "PathToImgs = 'data-object2vec/stimuli'\n",
    "savepath = '../../../data-14/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only the subset\n",
    "datapath = '../../../data-04/'\n",
    "nsample = 12\n",
    "WrdThingsInfo = pd.read_csv(datapath + 'KeptTHINGSInfo_n' + str(nsample) +'.csv',sep=',',index_col = 0)\n",
    "WordInfThings = WrdThingsInfo.Word.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute DNN features\n",
    "def object_by_feature(PathToImgs,keyword,ilayer,resolutionval,cropval, savepath,WordInf=[],pretrained=True):\n",
    "    if pretrainedModel:\n",
    "        namefile = savepath+ keyword + '_' + ilayer \n",
    "    else:\n",
    "        namefile = savepath+ keyword + '_' + ilayer +\"_untrained\"\n",
    "        \n",
    "    if os.path.isfile(namefile+\".csv\"): #if it's already saved\n",
    "        \n",
    "        print('loading file with '+ keyword+ ' stimuli features for ' + ilayer)\n",
    "        features = pd.read_csv(namefile+\".csv\"  , sep=\",\", header=None, index_col=0)\n",
    "        condition_features = {}\n",
    "        for index, row in features.iterrows():\n",
    "            condition_features[index] = row \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if keyword == 'things':\n",
    "            WordInf = WordInfThings\n",
    "        \n",
    "        \n",
    "        print('Computing '+ keyword+ ' stimuli features for ' + ilayer)\n",
    "        #Specify the model\n",
    "        model = emfe.AlexNet(ilayer,pretrained_val=pretrained);      \n",
    "        condition_features = emutils.compute_features(model, PathToImgs,resolutionval,cropval,WordInf)\n",
    "#         features = \n",
    "        pd.DataFrame(condition_features).transpose().to_csv(namefile+\".csv\", index = True, header=False)\n",
    "#         features.to_csv(namefile+\".csv\", index = True, header=False)\n",
    "        np.save(namefile,condition_features)\n",
    "#     layer_by_features[ilayer] = features; #create multistructure with all layers\n",
    "    return condition_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "pretrainedModel = True\n",
    "resolutionval = 256;\n",
    "cropval = 224;\n",
    "\n",
    "\n",
    "layer = {'conv_5'};\n",
    "ROI = {'EVC', 'LOC','PPA','OPA', 'PPA'}\n",
    "\n",
    "Sub = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ilayer in layer:    \n",
    "\n",
    "     #Compute features of CNN\n",
    "     #---------Object2Vect-----------------\n",
    "    keyword = 'object2vec'\n",
    "    object2vec_features = object_by_feature(PathToImgs,keyword,ilayer,resolutionval,cropval,savepath,pretrained=pretrainedModel)\n",
    "    \n",
    "#     #---------THINGS-----------------\n",
    "    keyword = 'things'\n",
    "    things_features = object_by_feature(pathtoTHINGS,keyword,ilayer,resolutionval,cropval,savepath,pretrained=pretrainedModel)\n",
    "    things_features_df = pd.DataFrame(things_features).transpose()\n",
    "    \n",
    "    for iSub in Sub:\n",
    "        for iROI in ROI:\n",
    "            subject = Subject(iSub,[iROI])\n",
    "            #predict fMRI using object2vec DNN activations\n",
    "            weights, r = cv_regression(object2vec_features, subject, l2=0)\n",
    "            if pretrainedModel:\n",
    "                np.save(savepath + '/Weights_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer , weights)\n",
    "            else:\n",
    "                np.save(savepath + '/Weights_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer + '_untrained', weights)\n",
    "                \n",
    "            \n",
    "            #     #---Compute Predicted ROI response to THINGS dataset\n",
    "            print(\"Computing ROI \" + iROI + \" prediction for \" + ilayer)    \n",
    "            ROIpred = {}\n",
    "            ROIpred = np.matmul(things_features_df.iloc[:,:].to_numpy(),weights.transpose())\n",
    "            \n",
    "            if pretrainedModel:\n",
    "                np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer, ROIpred)\n",
    "            else:\n",
    "                np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer + '_untrained', ROIpred)\n",
    "print('things dataset activations in DNN '+ ilayer +' size: ' + str(things_features_df.shape))\n",
    "print('weights size: ' + str(weights.shape))\n",
    "print('ROI pred size: ' + str(ROIpred.shape))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do it for random weights - permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utilsCM\n",
    "import matplotlib.pyplot as plt\n",
    "# #Parameters\n",
    "pretrainedModel = True\n",
    "resolutionval = 227;\n",
    "\n",
    "\n",
    "layer = {'conv_5'};\n",
    "ROI = {'EVC', 'LOC','PPA','OPA', 'PPA'}\n",
    "Sub = [1,2,3,4]\n",
    "\n",
    "iters = 500\n",
    "Randomstep = 'permuteFeats' #'permuteFeats' #covMatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading file with object2vec stimuli features for conv_5\n",
      "loading file with things stimuli features for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI PPA prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI LOC prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI OPA prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI EVC prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI PPA prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI LOC prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI OPA prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI EVC prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI PPA prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI LOC prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI OPA prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI EVC prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI PPA prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI LOC prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI OPA prediction for conv_5\n",
      "computing Cv regression\n",
      "computing randomMatrix\n",
      "computed randomMatrix\n",
      "Computing ROI EVC prediction for conv_5\n",
      "things dataset activations in DNN conv_5 size: (312, 9216)\n",
      "weights size: (200, 9216)\n",
      "ROI pred size: (312, 200)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for ilayer in layer:    \n",
    "\n",
    "     #Compute features of CNN\n",
    "     #---------Object2Vect-----------------\n",
    "    keyword = 'object2vec'\n",
    "    object2vec_features = object_by_feature(PathToImgs,keyword,ilayer,resolutionval,cropval,savepath,pretrained=pretrainedModel)\n",
    "    \n",
    "#     #---------THINGS-----------------\n",
    "    keyword = 'things'\n",
    "    things_features = object_by_feature(pathtoTHINGS,keyword,ilayer,resolutionval,cropval,savepath,pretrained=pretrainedModel)\n",
    "    things_features_df = pd.DataFrame(things_features).transpose()\n",
    "    \n",
    "    for iSub in Sub:\n",
    "        for iROI in ROI:\n",
    "            subject = Subject(iSub,[iROI])\n",
    "            #predict fMRI using object2vec DNN activations\n",
    "            print('computing Cv regression')\n",
    "            weights, r = cv_regression(object2vec_features, subject, l2=0)\n",
    "            savefigname = keyword  + '_Sub'+str(iSub)+ '_' +iROI + '_'+ ilayer\n",
    "            plt.imshow(weights[:,0:250])\n",
    "            plt.title(savefigname)\n",
    "            plt.savefig(savepath + savefigname + '.png') \n",
    "            plt.close(\"all\")\n",
    "            \n",
    "            \n",
    "            #Do the random step\n",
    "            if Randomstep is 'covMatching':\n",
    "                print('computing randomMatrix')\n",
    "                weights = utilsCM.RandomCovMatrix(weights)\n",
    "                savefigname = keyword  + '_Sub'+str(iSub)+ '_' +iROI + '_'+ ilayer + 'random'\n",
    "                plt.imshow(weights[:,0:250])\n",
    "                plt.title(savefigname)\n",
    "                plt.savefig(savepath + savefigname + '.png') \n",
    "                plt.close(\"all\")\n",
    "                \n",
    "                np.save(savepath + '/Weights_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer + '_' + Randomstep, weights)\n",
    "                print('computed randomMatrix')\n",
    "#             if ilayer is not 'conv_1':\n",
    "                savefigname = keyword + '_Sub'+str(iSub)+'_' +iROI + '_'+ ilayer + '_random'\n",
    "                plt.imshow(weights[:,0:250])\n",
    "                plt.title(savefigname)\n",
    "                plt.savefig(savepath + savefigname + '.png') \n",
    "                plt.close(\"all\")\n",
    "                \n",
    "                #     #---Compute Predicted ROI response to THINGS dataset\n",
    "                print(\"Computing ROI \" + iROI + \" prediction for \" + ilayer)    \n",
    "                ROIpred = {}\n",
    "                ROIpred = np.matmul(things_features_df.iloc[:,:].to_numpy(),weights.transpose())\n",
    "                \n",
    "                \n",
    "            elif Randomstep is 'permuteFeats':\n",
    "                print('permuting Features')\n",
    "                ROIpred = utilsCM.PermuteFeats(weights,things_features_df.iloc[:,:].to_numpy(), iters)\n",
    "            \n",
    "            \n",
    "            #save ROIpred\n",
    "            np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer + '_' + Randomstep, ROIpred)\n",
    "            \n",
    "print('things dataset activations in DNN '+ ilayer +' size: ' + str(things_features_df.shape))\n",
    "print('weights size: ' + str(weights.shape))\n",
    "print('ROI pred size: ' + str(ROIpred.shape))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_features_df.iloc[:,:].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.transpose().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIpred = np.matmul(things_features_df.iloc[:,:].to_numpy(),weights.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "things_features_df.iloc[:,:].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Randomstep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer + '_' + Randomstep, ROIpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 13.005 ,   5.355 , -10.659 ],\n",
       "       [  5.355 ,   2.205 ,  -4.389 ],\n",
       "       [-10.659 ,  -4.389 ,   8.7362]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = [-2.1, -1,  4.3]\n",
    "y = [3,  1.1,  0.12]\n",
    "X = np.stack((x, y), axis=0)\n",
    "cov_ = np.cov(X, rowvar = False)\n",
    "cov_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ = X.mean(axis=0)\n",
    "mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal(mean_, cov_, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
