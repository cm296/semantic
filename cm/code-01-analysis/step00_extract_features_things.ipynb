{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "sys.path.append('/Users/cmagri1/OneDrive - Johns Hopkins/git')\n",
    "from torch import nn\n",
    "import torch\n",
    "from torchvision.models.alexnet import alexnet\n",
    "from tqdm import tqdm\n",
    "\n",
    "from EncodingModel_cm296 import utils as emutils\n",
    "from EncodingModel_cm296 import feature_extractor as emfe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from utilsCM import Subject\n",
    "from utilsCM import cv_regression #Predicting fMRI reponses with features (Alexnet activations) \n",
    "#cv_regression computes cross-validated ridge regression. cross-validation groupings were pre-set based\n",
    "#on fMRI design. 9-categories out, 9 folds. r is averaged over folds, weights are computed over all data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify variables\n",
    "resolutionval = 227;\n",
    "# print(model)\n",
    "\n",
    "#sepcify directory where images (for which we have fMRI data) are\n",
    "PathToImgs = 'data-object2vec/stimuli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load word2sense\n",
    "#already preprocessed in MATLAB so that Wrd2Sns and THINGs overlap --> we have IMAGES, LABELS and SENSES\n",
    "pathtofile = '../code-00-preprocessdataset/'\n",
    "Wrd2Sense = pd.read_csv(pathtofile + \"ThingsWrd2Sns.txt\", sep=\",\")\n",
    "ImgInfo = pd.read_csv(pathtofile + \"KeptTHINGSInfo.txt\", sep=\",\")\n",
    "WordInf= ImgInfo.Word.to_numpy() ##to find the words that are images in THINGS dataset\n",
    "pathtoTHINGS = '/Users/cmagri1/OneDrive - Johns Hopkins/Project-Word2Sense/THINGSdataset/Main/images'\n",
    "savepath = '../../../data-00/'\n",
    "pretrainedModel = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute DNN features\n",
    "def object_by_feature(PathToImgs,keyword,ilayer,resolutionval, savepath,WordInf=[],pretrained=True):\n",
    "    if os.path.isfile(savepath+ keyword + '_' + ilayer +\"_untrained\"+ \".csv\"):\n",
    "        print('loading file with '+ keyword+ ' stimuli features for ' + ilayer)\n",
    "        features = pd.read_csv(savepath+ keyword + \"_\" + ilayer + \".csv\"  , sep=\",\", header=None, index_col=0)\n",
    "#         features = pd.read_csv(datapath+ keyword + \"_\" + ilayer + \".csv\"  , sep=\",\", header=None)\n",
    "\n",
    "        condition_features = {}\n",
    "        for index, row in features.iterrows():\n",
    "            condition_features[index] = row \n",
    "    else:\n",
    "        print('Computing '+ keyword+ ' stimuli features for ' + ilayer)\n",
    "        \n",
    "        #Specify the model\n",
    "        model = emfe.AlexNet(ilayer,pretrained_val=pretrained); \n",
    "        \n",
    "        if WordInf != np.array([]):\n",
    "            condition_features = emutils.compute_features(model, PathToImgs,resolutionval,WordInf)\n",
    "        else:\n",
    "            condition_features = emutils.compute_features(model, PathToImgs,resolutionval)\n",
    "        features = pd.DataFrame(condition_features).transpose() \n",
    "        \n",
    "        if pretrained:\n",
    "            features.to_csv(savepath + keyword+ \"_\" + ilayer+ \".csv\", index = True, header=False)\n",
    "            np.save(savepath + keyword+ \"_\" + ilayer,condition_features)\n",
    "        else:\n",
    "            features.to_csv(savepath + keyword+ \"_\" + ilayer +\"_untrained\"+ \".csv\", index = True, header=False)\n",
    "            np.save(savepath + keyword+ \"_\" + ilayer+\"_untrained\",condition_features)\n",
    "#     layer_by_features[ilayer] = features; #create multistructure with all layers\n",
    "    return condition_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer = {'conv_1','conv_2','conv_3','conv_4','conv_5','fc_1','fc_2','fc_3'};\n",
    "layer = {'conv_1','conv_5'};\n",
    "\n",
    "ROI = {'PPA'}\n",
    "Sub = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ilayer in layer:    \n",
    "\n",
    "     #Compute features of CNN\n",
    "     #---------Object2Vect-----------------\n",
    "    keyword = 'object2vec'\n",
    "    object2vec_features = object_by_feature(PathToImgs,keyword,ilayer,resolutionval,savepath,pretrained=pretrainedModel)\n",
    "#     #---------THINGS-----------------\n",
    "    keyword = 'things'\n",
    "    things_features = object_by_feature(pathtoTHINGS,keyword,ilayer,resolutionval,savepath,pretrained=pretrainedModel)\n",
    "    things_features_df = pd.DataFrame(things_features).transpose()\n",
    "    \n",
    "    for iSub in Sub:\n",
    "        for iROI in ROI:\n",
    "            subject = Subject(iSub,[iROI])\n",
    "            #predict fMRI using object2vec DNN activations\n",
    "            weights, r = cv_regression(object2vec_features, subject, l2=0)\n",
    "            \n",
    "            #     #---Compute Predicted ROI response to THINGS dataset\n",
    "            print(\"Computing ROI \" + iROI + \" prediction for \" + ilayer)    \n",
    "            ROIpred = {}\n",
    "            ROIpred = np.matmul(things_features_df.iloc[:,:].to_numpy(),weights.transpose())\n",
    "            \n",
    "            if pretrainedModel:\n",
    "                np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer, ROIpred)\n",
    "            else:\n",
    "                np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer + '_untrained', ROIpred)\n",
    "print('things dataset activations in DNN '+ ilayer +' size: ' + str(things_features_df.shape))\n",
    "print('weights size: ' + str(weights.shape))\n",
    "print('ROI pred size: ' + str(ROIpred.shape))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
